Test Locally first:
(1) cat shakespeare.txt
(2) cat shakespeare.txt |python3 mapper.py
(3) cat shakespeare.txt |python3 mapper.py |sort |python3 reducer.py


Step by step Commands:
(1) Ensure data_330 , namespace_logs_330 are both empty

(2) Open terminal as admin, cd to C:\hadoop-3.3.0\sbin

(3) hdfs namenode -format

(2) ./start-dfs.sh 
    for windows: start-dfs.cmd

(3) ./start-yarn.sh
        start-yarn.cmd

(4) hdfs dfs -mkdir -p inputtext

(5) hdfs dfs -put C:/Users/Khaled/Documents/University/Years/Masters/MIE1628/Assigments/Assignment_1/Q1/shakespeare.txt inputtext

(6) hadoop jar C:/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -file C:/Users/Khaled/Documents/University/Years/Masters/MIE1628/Assigments/Assignment_1/Q1/mapper.py -mapper "C:\Users\Khaled\AppData\Local\Microsoft\WindowsApps\python3.exe C:/Users/Khaled/Documents/University/Years/Masters/MIE1628/Assigments/Assignment_1/Q1/mapper.py" -file C:/Users/Khaled/Documents/University/Years/Masters/MIE1628/Assigments/Assignment_1/Q1/reducer.py -reducer "C:\Users\Khaled\AppData\Local\Microsoft\WindowsApps\python3.exe C:/Users/Khaled/Documents/University/Years/Masters/MIE1628/Assigments/Assignment_1/Q1/reducer.py" -input inputtext -output outputcount

(7) hdfs dfs -cat outputcount/part-00000

To quit:
    /stop-yarn.cmd
    /stop-dfs.cmd